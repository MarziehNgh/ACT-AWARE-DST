{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruolin/anaconda3/envs/allen090/lib/python3.6/site-packages/allennlp/service/predictors/__init__.py:23: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\n",
      "  \"Please use allennlp.predictors.*\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "from act_aware_dst.act_dst import ADST\n",
    "from act_aware_dst.act_dst_reader import ADSTReader\n",
    "from act_aware_dst.act_dst_predictor import ADSTPredictor\n",
    "\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.service.predictors import Predictor\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from allennlp.modules.matrix_attention.linear_matrix_attention import LinearMatrixAttention\n",
    "from allennlp.nn import util\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruolin/anaconda3/envs/allen090/lib/python3.6/site-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1836])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "archive = load_archive('model_act_512/model.tar.gz')\n",
    "\n",
    "parameters = {}\n",
    "attention_weight = {}\n",
    "for n, p in archive.model.named_parameters():\n",
    "    if '_ds_attention._weight_vector'==n:\n",
    "        print(p.size())\n",
    "        weights = p.data\n",
    "        attention_weight[\"_weight_vector\"] = p\n",
    "    if '_ds_attention._bias'==n:\n",
    "        print(p.size())\n",
    "        bias = p.data\n",
    "        attention_weight[\"_bias\"] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_file=\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x2048_256_2048cnn_1xhighway/elmo_2x2048_256_2048cnn_1xhighway_options.json\"\n",
    "weight_file=\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x2048_256_2048cnn_1xhighway/elmo_2x2048_256_2048cnn_1xhighway_weights.hdf5\"\n",
    "\n",
    "# Note the \"1\", since we want only 1 output representation for each token.\n",
    "elmo = Elmo(options_file, weight_file, 1, dropout=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use batch_to_ids to convert sentences to character ids\n",
    "acts = [[\"select\",\"recommend\", \"reqmore\",\"book\",\"offerbook\",\"offerbooked\",\"nooffer\",\"greet\",\"bye\",\"request\",\"inform\",\"welcome\",\"nobook\"]]\n",
    "acts =  [[\"welcome\",\"select\",\"recommend\",\"recommand\"]]\n",
    "ds =  [['restaurant area'], ['restaurant pricerange'], ['restaurant food'], ['restaurant name'], ['restaurant bookpeople'], \\\n",
    "  ['restaurant booktime'], ['restaurant bookday'],[ 'hotel pricerange'], ['hotel type'], ['hotel parking'], \n",
    "  ['hotel bookstay'], ['hotel bookday'], ['hotel  bookpeople'], ['hotel  area'], ['hotel  stars'], \\\n",
    "  ['hotel internet'], ['hotel name'], ['train destination'], ['train departure'], ['train day'], \\\n",
    "  ['train arriveby'], ['train leaveat'], ['train bookpeople'], ['attraction area'], ['attraction name'], \n",
    "  ['attraction type'], ['taxi destination'], ['taxi departure'], ['taxi arriveby'], ['taxi leaveat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 512])\n",
      "torch.Size([30, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "acts_char_ids = batch_to_ids(acts)\n",
    "ds_char_ids = batch_to_ids(ds)\n",
    "\n",
    "acts_embeddings = elmo(acts_char_ids)\n",
    "ds_embeddings = elmo(ds_char_ids)\n",
    "\n",
    "print(acts_embeddings[\"elmo_representations\"][0].shape)\n",
    "print(ds_embeddings[\"elmo_representations\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "#dialog_scalar_mix = ScalarMix(mixture_size=3, trainable=False)\n",
    "ds_attention= LinearMatrixAttention(612, 612, 'x,y,x*y')\n",
    "ds_attention.load_state_dict(attention_weight)\n",
    "\n",
    "num_acts = len(acts[0])\n",
    "act_value_sim = ds_attention(ds_embeddings[\"elmo_representations\"][0],acts_embeddings[\"elmo_representations\"][0].repeat(len(ds),1,1))\n",
    "act_att_scores = util.masked_softmax(act_value_sim.view(-1,num_acts),None)\n",
    "act_att_scores = act_att_scores.view(len(ds), 1, num_acts)\n",
    "act_att_array = act_att_scores.cpu().detach().numpy()\n",
    "print(act_att_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = act_att_scores.squeeze(1).cpu().detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.matshow(matrix)\n",
    "\n",
    "ax.set_xticks(np.arange(len(acts[0])))\n",
    "ax.set_yticks(np.arange(len(ds)))\n",
    "ds_list = [x[0] for x in ds]\n",
    "#ds_list= list(range(1,30+1))\n",
    "ax.xaxis.tick_bottom()\n",
    "ax.set_xticklabels(acts[0], rotation=90,fontsize=8)\n",
    "ax.set_yticklabels(ds_list,fontsize=8)\n",
    "\n",
    "fig.tight_layout()\n",
    "ax.set_title(\"Slots and Acts Attention\")\n",
    "plt.savefig(f\"output/attention_10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allen090",
   "language": "python",
   "name": "allen090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
